
Dynamic insert
---------------

INSERT OVERWRITE TABLE sales PARTITION(dop='2015-10-20', city) SELECT slr.id, slr.firstname, slr.lastname, slr.city FROM sales_region slr

SET hive.exec.dynamic.partition = true;
SET hive.exec.dynamic.partition.mode = nonstrict;

writing to dir
---------------
INSERT OVERWRITE [LOCAL] DIRECTORY directory1 [ROW FORMAT row_format] [STORED AS file_format]SELECT select_statment FROM from_statment.

external partitioning
----------------------
CREATE EXTERNAL TABLE customer_external(id STRING, name STRING, gender STRING, state STRING) PARTITIONED BY (country STRING);
ALTER TABLE customer_external ADD PARTITION(country='UK') LOCATION '/user/hive/warehouse/customer/country=UK'

Bucketing
---------

set hive.enforce.bucketing=true;

CREATE [EXTERNAL] TABLE [db_name.]table_name
    [(col_name data_type [COMMENT col_comment], ...)]
    CLUSTERED BY (col_name data_type [COMMENT col_comment], ...)
INTO N BUCKETS;

Joins
-----

SELECT a.* FROM Sales a JOIN Sales_orc b ON a.id = b.id;
SELECT a.fname, b.lname, c.address FROM Sales a JOIN Sales_orc b ON a.id = b.id join Sales_info c ON c.id = b.id;
SELECT a.fname, b.lname, c.address FROM Sales a JOIN Sales_orc b ON a.id = b.id join Sales_info c ON c.address = b.address;

SELECT * FROM Sales a LEFT OUTER JOIN Sales_orc b ON a.id = b.id;

SELECT * FROM Sales a RIGHT OUTER JOIN Sales_orc b ON a.id = b.id;

SELECT * FROM Sales a FULL OUTER JOIN Sales_orc b ON a.id = b.id;

SELECT * FROM Sales a LEFT OUTER JOIN Sales_orc b ON a.id = b.id WHERE a.fname = 'John';

SELECT * FROM Sales a RIGHT OUTER JOIN Sales_orc b ON a.id = b.id WHERE a.fname = 'John';

Left Semi Join
---------------
Used in place of IN/EXISTS
In the left semi join, the right-hand side table can only be used in the join clause but not in the WHERE or the SELECT clause

SELECT a.* FROM Sales a LEFT SEMI JOIN Sales_orc b ON a.id = b.id;

SELECT a.*, b.* FROM Sales a LEFT SEMI JOIN Sales_orc b ON a.id = b.id;

SELECT a.* FROM Sales a LEFT SEMI JOIN Sales_orc b ON a.id = b.id WHERE b.id = 1;

Mapside Join
-------------

Old way:/*+ MAPJOIN(<table_name>)*/
 set hive.auto.convert.join=true;
 
 SELECT /*+ MAPJOIN(Sales_orc)*/ a.fname, b.lname FROM Sales a JOIN Sales_orc b ON a.id = b.id;
SELECT a.* FROM Sales a JOIN Sales_orc b ON a.id = b.id and a.fname = b.fname;

Serde
-----
Download jar from http://www.congiu.net/hive-json-serde/1.3.8/cdh5/

CREATE EXTERNAL TABLE empljson (empid int,empname string,emploc string)
ROW FORMAT SERDE 'org.openx.data.jsonserde.JsonSerDe'
WITH SERDEPROPERTIES ("empid"="$.empid","empname"="$.empname","emploc"="$.emploc") LOCATION '/user/cloudera/serdedata/';

UDF
----
CREATE EXTERNAL TABLE sampleTbl(empdet String,dept string)
    > ROW FORMAT DELIMITED FIELDS TERMINATED BY '|' STORED AS TEXTFILE 
    > LOCATION '/user/cloudera/serdedata/sample1';

get_json_object()

select get_json_object(sampleTbl.empdet,"$.empid") as empid,get_json_object(sampleTbl.empdet,"$.empname") as empname ,dept from sampleTbl;

CustomUDF
---------
1. Create a class by extending UDF and override evaluate() function. Sample is below
    https://github.com/nk-dasari/CustomUDF/blob/master/src/main/java/com/hadoop/training/Lower.java
2. In hive prompt do the following
    hive> ADD JAR /path/to/CustomUDF-0.0.1-SNAPSHOT.jar;
    hive> create temporary function lwr as 'com.hadoop.training.Lower';
    hive> select lwr(colname) from tablename limit 10;

